{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.book import *\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "import random\n",
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "import seaborn as sns\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "sns.set_context('notebook')\n",
    "import warnings\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### get all csv dataframes for trending\n",
    "US_trending_df = pd.read_csv('youtube-new/USvideos.csv') #USA\n",
    "CA_trending_df = pd.read_csv('youtube-new/CAvideos.csv') #CANADA\n",
    "DE_trending_df = pd.read_csv('youtube-new/DEvideos.csv') #GERMANY\n",
    "FR_trending_df = pd.read_csv('youtube-new/FRvideos.csv') #FRANCE\n",
    "GB_trending_df = pd.read_csv('youtube-new/GBvideos.csv') #GREAT BRITAIN\n",
    "IN_trending_df = pd.read_csv('youtube-new/INvideos.csv') #INDIA\n",
    "\n",
    "# JP_trending_df = pd.read_csv('youtube-new/JPvideos.csv', encoding=\"UTF-8\") #JAPAN\n",
    "\n",
    "# KR_trending_df = pd.read_csv('youtube-new/KRvideos.csv') #SOUTH KOREA\n",
    "\n",
    "# MX_trending_df = pd.read_csv('youtube-new/MXvideos.csv') #MEXICO\n",
    "\n",
    "# RU_trending_df = pd.read_csv('youtube-new/RUvideos.csv') #RUSSIA\n",
    "\n",
    "list_of_all_trending_dfs = [US_trending_df, CA_trending_df, DE_trending_df, FR_trending_df, GB_trending_df, IN_trending_df]\n",
    "full_trending_df = pd.concat(list_of_all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"apiKey\", \"r\")\n",
    "key = f.read()\n",
    "## for each videoId, find a related video\n",
    "def do_search_youtube_request(videoId):\n",
    "    url = \"https://www.googleapis.com/youtube/v3/search?part=snippet&maxResults=2&order=relevance&relatedToVideoId={}&type=video&videoDefinition=any&key={}\".format(videoId, key)\n",
    "    r = requests.get(url)\n",
    "    return r\n",
    "\n",
    "## given a set of videoIds, find insights (statistics, tags, etc)\n",
    "def find_video_insights(videoIds):\n",
    "    print(videoIds)\n",
    "    url = 'https://www.googleapis.com/youtube/v3/videos?part=snippet%2CcontentDetails%2Cstatistics&id={}&key={}'.format(videoIds, key)\n",
    "    r = requests.get(url)\n",
    "    return r\n",
    "\n",
    "## call this with 1 country at a time \n",
    "def process_youtube_requests(videoIds):\n",
    "    df = pd.DataFrame(columns=['video_id', 'title', 'channel_title', 'category_id', 'publish_time', 'tags', \n",
    "                               'views', 'likes', 'dislikes', 'comment_count', 'description'])\n",
    "    relatedVideoIds = []\n",
    "    responses = []\n",
    "    for videoId in videoIds:\n",
    "        try: \n",
    "            response = do_search_youtube_request(videoId)\n",
    "            if (response.status_code == 200):\n",
    "                r1 = response.json()\n",
    "                relatedVideoId = r1['items'][0]['id']['videoId']\n",
    "                relatedVideoIds.append(str(relatedVideoId))\n",
    "            else:\n",
    "                print(response.status_code)\n",
    "        except:\n",
    "            print (\"Something went wrong here! 2\")\n",
    "    print (relatedVideoIds)\n",
    "    videoIdsStr = '%2C'.join([str(elem) for elem in relatedVideoIds])\n",
    "    r2 = find_video_insights(videoIdsStr)\n",
    "    if (r2.status_code == 200):\n",
    "        r = r2.json()\n",
    "        i = 0\n",
    "        while (i < len(relatedVideoIds)):\n",
    "            try:\n",
    "                id = relatedVideoIds[i]\n",
    "                title = (r['items'][i]['snippet']['title'])\n",
    "                channel_title = (r['items'][i]['snippet']['channelTitle'])\n",
    "                category_id = (r['items'][i]['snippet']['categoryId'])\n",
    "                publish_time = (r['items'][i]['snippet']['publishedAt'])\n",
    "                tags = '|'.join((r['items'][i]['snippet']['tags']))\n",
    "                views = (r['items'][i]['statistics']['viewCount'])\n",
    "                likes = (r['items'][i]['statistics']['likeCount'])\n",
    "                dislikes = (r['items'][i]['statistics']['dislikeCount'])\n",
    "                comment_count = (r['items'][i]['statistics']['commentCount'])\n",
    "                description = (r['items'][i]['snippet']['description'])\n",
    "                data = {'video_id': id, 'title': title, 'channel_title': channel_title, 'category_id' : category_id,\n",
    "                       'publish_time' : publish_time, 'tags' : tags, 'views' : views, 'likes' : likes, 'dislikes' : dislikes,\n",
    "                       'comment_count' : comment_count, 'description' : description}\n",
    "                df = df.append(data, ignore_index = True)\n",
    "            except:\n",
    "                print(\"Something went wrong! 3\")\n",
    "            i = i + 1\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "US_trending_videoIds = US_trending_df.sample(n)['video_id'].tolist()\n",
    "CA_trending_videoIds = CA_trending_df.sample(n)['video_id'].tolist()\n",
    "DE_trending_videoIds = DE_trending_df.sample(n)['video_id'].tolist()\n",
    "FR_trending_videoIds = FR_trending_df.sample(n)['video_id'].tolist()\n",
    "GB_trending_videoIds = GB_trending_df.sample(n)['video_id'].tolist()\n",
    "IN_trending_videoIds = IN_trending_df.sample(n)['video_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do following requests separately with a new API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_trending_us_df = process_youtube_requests(US_trending_videoIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_trending_ca_df = process_youtube_requests(CA_trending_videoIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_trending_de_df = process_youtube_requests(DE_trending_videoIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_trending_fr_df = process_youtube_requests(FR_trending_videoIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_trending_gb_df = process_youtube_requests(GB_trending_videoIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_trending_in_df = process_youtube_requests(IN_trending_videoIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_nontrending_dfs = [non_trending_us_df, not_trending_ca_df, not_trending_de_df, \n",
    "                              not_trending_fr_df, not_trending_gn_df, not_trending_in_df]\n",
    "full_nontrending_df = pd.concat(list_of_all_nontrending_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_category_field(df, json_file):\n",
    "    # add a category column using the category id from the json file\n",
    "    id_to_category = {}\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        for category in data['items']:\n",
    "            id_to_category[category['id']] = category['snippet']['title']\n",
    "        df.insert(4, 'category', us['category_id'].map(id_to_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert new category field into dataframes\n",
    "insert_category_field(US_trending_df, \"US_category_id.json\")\n",
    "insert_category_field(CA_trending_df, \"CA_category_id.json\")\n",
    "insert_category_field(DE_trending_df, \"DE_category_id.json\")\n",
    "insert_category_field(FR_trending_df, \"FR_category_id.json\")\n",
    "insert_category_field(GB_trending_df, \"GB_category_id.json\")\n",
    "insert_category_field(IN_trending_df, \"IN_category_id.json\")\n",
    "\n",
    "insert_category_field(not_trending_us_df, \"US_category_id.json\")\n",
    "insert_category_field(not_trending_ca_df, \"CA_category_id.json\")\n",
    "insert_category_field(not_trending_de_df, \"DE_category_id.json\")\n",
    "insert_category_field(not_trending_fr_df, \"FR_category_id.json\")\n",
    "insert_category_field(not_trending_gb_df, \"GB_category_id.json\")\n",
    "insert_category_field(not_trending_in_df, \"IN_category_id.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do following for both trending and nontrending datasets and/or per country\n",
    "## do good visualizations for all!!!\n",
    "\n",
    "## find likes to dislikes ratio ---> shows where people have the greatest divide and where people agree the most \n",
    "## which categories are the most popular? do highest average amongst likes and views ----> shows which type of videos people enjoy the most\n",
    "## most trending videos in each country? do average amongst likes, views ------> shows most trending videos per country\n",
    "## how long did a video stay trending? how long did it take to become trending?\n",
    "## which country has the most active participation and online presence across trending and nontrending? ----> min, max, std, quartiles, counts, etc\n",
    "## correlation between views, likes, dislikes, and comments\n",
    "## get most frequent tags ----> run sentiment analysis on tags, run LDA model on tags\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
